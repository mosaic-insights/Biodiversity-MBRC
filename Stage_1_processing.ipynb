{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SETUP ###\n",
    "\n",
    "import arcpy\n",
    "from arcgis import gis\n",
    "import pandas as pd\n",
    "from arcpy.sa import *\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.workspace = 'BiodiversityMBRC.gdb'\n",
    "gdb = arcpy.env.workspace\n",
    "\n",
    "### FUNCTIONS ###\n",
    "\n",
    "# spatial join function that allows you to input fields to join\n",
    "def simpleSpatialJoin(fcA, fcB, fcOut, fieldsToJoin, joinType, keepType):\n",
    "    # Get field mappings of input dataset\n",
    "    mapA = arcpy.FieldMappings()\n",
    "    mapA.addTable(fcA)\n",
    "    # Get field mappings of join dataset\n",
    "    mapB = arcpy.FieldMappings()\n",
    "    mapB.addTable(fcB)\n",
    "    # Get index of sensitivity score field and add to field map. Define merge rule.\n",
    "    for field in fieldsToJoin:\n",
    "        ind = mapB.findFieldMapIndex(field)\n",
    "        fmap = mapB.getFieldMap(ind)\n",
    "        fmap.mergeRule = 'First'\n",
    "        mapA.addFieldMap(fmap)\n",
    "    # Run spatial join\n",
    "    if joinType == 'JOIN_ONE_TO_ONE':\n",
    "        match = 'LARGEST_OVERLAP'\n",
    "    else:\n",
    "        match = 'INTERSECT'\n",
    "    arcpy.analysis.SpatialJoin(fcA, fcB, fcOut, joinType, keepType, mapA, match, None, \"\")\n",
    "    \n",
    "def replaceNone(dataset, field):\n",
    "    with arcpy.da.UpdateCursor(dataset, field) as cursor:\n",
    "        for row in cursor:\n",
    "            if row[0] is None:\n",
    "                row[0] = 0\n",
    "                cursor.updateRow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MERGE VEGETATION COVER DATASETS\n",
    "\n",
    "if arcpy.Exists(\"Processing\"):\n",
    "    arcpy.Delete_management(\"Processing\")\n",
    "    \n",
    "arcpy.management.CreateFeatureDataset(gdb, 'Processing', arcpy.Describe(f'{gdb}/Input').spatialReference.name)\n",
    "    \n",
    "# create remnant vegetation layer\n",
    "arcpy.management.MakeFeatureLayer(\"Input/remnantVegetationCoverCouncilExtent\", \"remnantVeg\", \"Cover = 'remnant'\")\n",
    "\n",
    "# add Caboolture RRE\n",
    "arcpy.management.MakeFeatureLayer(\"Input/Refined_Regional_Ecosystem_Caboolture\", \"rreCaboolture\", \"VM_Status <> 'Water'\")\n",
    "# merge two RRE datasets\n",
    "arcpy.management.Merge(\"rreCaboolture;Input/Refined_Regional_Ecosystem_Narangba\", \"Processing/rreMerged\", \"\", \"ADD_SOURCE_INFO\")\n",
    "# dissolve RRE datasets and obtain minimum bounding geometry\n",
    "arcpy.analysis.PairwiseDissolve(\"rreMerged\", \"Processing/rreDiss\")\n",
    "arcpy.management.MinimumBoundingGeometry(\"rreDiss\", \"Processing/minBound\", \"CONVEX_HULL\")\n",
    "\n",
    "# use the MBG to erase features from remnant vegetation layer\n",
    "arcpy.analysis.PairwiseErase(\"remnantVeg\", \"minBound\", \"Processing/remnantVegErase\")\n",
    "# union the erased remnant veg layer and merged RRE layer\n",
    "arcpy.analysis.Union([\"remnantVegErase\", \"rreMerged\"], \"Processing/vegCoverSubUnion\")\n",
    "    \n",
    "# add High Value Regrowth in areas not covered by either remnant veg or RRE features\n",
    "arcpy.management.MakeFeatureLayer(\"Input/High_value_regrowth\", \"hvr\")\n",
    "# clip to council extent\n",
    "arcpy.analysis.PairwiseClip('hvr', 'Input/Council_Extent', 'Processing/hvrClipCouncil')\n",
    "# use unioned veg cover dataset as erase features\n",
    "arcpy.analysis.PairwiseErase(\"Processing/hvrClipCouncil\", \"vegCoverSubUnion\", \"Processing/hvrErase\")\n",
    "# combine\n",
    "try:\n",
    "    arcpy.analysis.Union([\"vegCoverSubUnion\", \"hvrErase\"], \"Basemap/vegCoverUnion\")\n",
    "except:\n",
    "    arcpy.management.Delete(\"Basemap/vegCoverUnion\")\n",
    "    arcpy.analysis.Union([\"vegCoverSubUnion\", \"hvrErase\"], \"Basemap/vegCoverUnion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SPATIAL JOIN CONTEXT LAYERS\n",
    "# create list of datasets to intersect and join areas to\n",
    "# RUNTIME ~20 minutes\n",
    "\n",
    "if arcpy.Exists(\"Processing\"):\n",
    "    arcpy.Delete_management(\"Processing\")\n",
    "\n",
    "arcpy.management.CreateFeatureDataset(gdb, 'Processing', arcpy.Describe(f'{gdb}/Input').spatialReference.name)\n",
    "\n",
    "dsets = ['Koala_habitat', 'Watercourse_area', 'Estuary', 'Reservoirs', 'Lakes', 'Canal_areas',\n",
    "        'LSI', 'Marine_swamp', 'Saline_coastal_flat', 'Swamp', 'Aquaculture', 'Settling_ponds', 'Salt_evaporators',\n",
    "         'Crayfish_pondage', 'Coastal_mngmnt_district', 'Shorebird_roosts', 'Riparian_woody_veg']\n",
    "\n",
    "arcpy.management.MakeFeatureLayer(\"Basemap/vegCoverUnion\", \"vegCoverUnion\")\n",
    "\n",
    "# pull out context layer datasets\n",
    "arcpy.management.MakeFeatureLayer('Input/Shorebird_Roosts', \"Shorebird_roosts\")\n",
    "arcpy.management.MakeFeatureLayer(\"Input/Watercourse_areas\", \"Watercourse_area\", \"TYPE = 2\")\n",
    "arcpy.management.MakeFeatureLayer(\"Input/Watercourse_areas\", \"Estuary\", \"TYPE = 4\")\n",
    "arcpy.management.MakeFeatureLayer(\"Input/Flats\", \"LSI\", \"TYPE = 1\")\n",
    "arcpy.management.MakeFeatureLayer(\"Input/Flats\", \"Marine_swamp\", \"TYPE = 2\")\n",
    "arcpy.management.MakeFeatureLayer(\"Input/Flats\", \"Saline_coastal_flat\", \"TYPE = 3\")\n",
    "arcpy.management.MakeFeatureLayer(\"Input/Flats\", \"Swamp\", \"TYPE = 4\")\n",
    "arcpy.management.MakeFeatureLayer('Input/Reservoirs', \"Reservoirs\")\n",
    "arcpy.management.MakeFeatureLayer('Input/Lakes', \"Lakes\")\n",
    "arcpy.management.MakeFeatureLayer('Input/Canal_areas', \"Canal_areas\")\n",
    "arcpy.management.MakeFeatureLayer('Input/Pondage', \"Aquaculture\", \"TEXTNOTE = 'aquaculture'\")\n",
    "arcpy.management.MakeFeatureLayer('Input/Pondage', \"Settling_ponds\", \"TEXTNOTE IN ('settling pond', 'settling ponds')\")\n",
    "arcpy.management.MakeFeatureLayer('Input/Pondage', \"Salt_evaporators\", \"TEXTNOTE = 'salt_evaporator'\")\n",
    "arcpy.management.MakeFeatureLayer('Input/Pondage', \"Crayfish_pondage\", \"TEXTNOTE = 'crayfish'\")\n",
    "arcpy.management.MakeFeatureLayer('Input/Coastal_plan_coastal_management_district', \"Coastal_mngmnt_district\")\n",
    "\n",
    "# merge koala habitat\n",
    "try:\n",
    "    arcpy.management.Merge(\"Input/koala_habitat_areas_v4_0;Input/locally_refined_koala_habitat_areas_v4_0\", 'Processing/Koala_habitat')\n",
    "except:\n",
    "    arcpy.management.Delete(\"Processing/Koala_habitat\")\n",
    "    arcpy.management.Merge(\"Input/koala_habitat_areas_v4_0;Input/locally_refined_koala_habitat_areas_v4_0\", 'Processing/Koala_habitat')\n",
    "\n",
    "# create riparian vegetation layer\n",
    "arcpy.management.MakeFeatureLayer('Input/Queensland_Woody_Extent_2021', \"woody_veg\", \"woody_extent_2021 = 1\")\n",
    "arcpy.management.MakeFeatureLayer('Input/riparianAreasMerged', \"ripZone\")\n",
    "if not arcpy.Exists(\"Input/riparian_woody_veg\"):\n",
    "    arcpy.analysis.PairwiseClip(\"woody_veg\", \"ripZone\", \"Input/riparian_woody_veg\")\n",
    "arcpy.management.MakeFeatureLayer(\"Input/riparian_woody_veg\", \"riparian_woody_veg\")\n",
    "\n",
    "# intersect context layers with vegetation cover\n",
    "for dset in dsets:\n",
    "    try:\n",
    "        arcpy.analysis.PairwiseDissolve(dset, f\"Processing/{dset}Diss\")\n",
    "    except:\n",
    "        arcpy.management.Delete(f\"Processing/{dset}Diss\")\n",
    "        arcpy.analysis.PairwiseDissolve(dset, f\"Processing/{dset}Diss\")\n",
    "    outInt = f\"Processing/vegInt{dset}\"\n",
    "    try:\n",
    "        arcpy.analysis.PairwiseIntersect([\"vegCoverUnion\", f\"Processing/{dset}Diss\"], outInt)\n",
    "    except:\n",
    "        arcpy.management.Delete(outInt)\n",
    "        arcpy.analysis.PairwiseIntersect([\"vegCoverUnion\", f\"Processing/{dset}Diss\"], outInt)\n",
    "    # join intersect area to vegetation cover dataset\n",
    "    if 'SHAPE_Area' in [field.name for field in arcpy.ListFields(outInt)]:\n",
    "        arcpy.management.CalculateField(outInt, f\"{dset}_area\", \"!SHAPE_Area!\", \"PYTHON3\", \"\", \"DOUBLE\")\n",
    "        arcpy.management.JoinField(\"vegCoverUnion\", \"OBJECTID\", outInt, \"FID_vegCoverUnion\", f\"{dset}_area\")\n",
    "        replaceNone(\"vegCoverUnion\", f\"{dset}_area\")\n",
    "    else:\n",
    "        arcpy.management.CalculateField(outInt, f\"{dset}_area\", \"!Shape_Area!\", \"PYTHON3\", \"\", \"DOUBLE\")\n",
    "        arcpy.management.JoinField(\"vegCoverUnion\", \"OBJECTID\", outInt, \"FID_vegCoverUnion\", f\"{dset}_area\")\n",
    "        replaceNone(\"vegCoverUnion\", f\"{dset}_area\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, 5 January 2024 9:50:03 AM\",\"Succeeded at Friday, 5 January 2024 9:50:03 AM (Elapsed Time: 0.13 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'vegCoverUnion'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create binary sea turtle nesting area attribute in veg cover. Use 50m to select turtle sites.\n",
    "arcpy.management.MakeFeatureLayer(\"Basemap/vegCoverUnion\", \"Sea_turtles\")\n",
    "arcpy.management.MakeFeatureLayer(\"Input/Sea_turtle_nesting_areas\", \"Sea_turtles\")\n",
    "arcpy.management.SelectLayerByLocation(\n",
    "    in_layer=\"vegCoverUnion\",\n",
    "    overlap_type=\"WITHIN_A_DISTANCE\",\n",
    "    select_features=\"Sea_turtles\",\n",
    "    search_distance=\"50 Meters\",\n",
    "    selection_type=\"NEW_SELECTION\",\n",
    "    invert_spatial_relationship=\"NOT_INVERT\"\n",
    ")\n",
    "arcpy.management.CalculateField(\"vegCoverUnion\", \"Sea_turtle_nesting_area\", \"'Yes'\", \"PYTHON3\")\n",
    "arcpy.management.SelectLayerByAttribute(\"vegCoverUnion\", \"CLEAR_SELECTION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarise watercourse lines length within veg cover\n",
    "#arcpy.management.MakeFeatureLayer('Input/Watercourse_lines_NE_Coast_drainage_division___southern_section', 'watercourse_lines')\n",
    "#arcpy.analysis.PairwiseDissolve(\"watercourse_lines\", \"Processing/watercourse_lines_diss\")\n",
    "#arcpy.analysis.PairwiseIntersect([\"vegCoverUnion\", \"watercourse_lines_diss\"], \"Processing/vegIntwatercourseLines\")\n",
    "\n",
    "arcpy.management.CalculateField(\"vegIntwatercourseLines\", \"watercourse_lines_length\", \"!Shape_Length!\", \"PYTHON3\", \"\", \"DOUBLE\")\n",
    "arcpy.management.JoinField(\"vegCoverUnion\", \"OBJECTID\", \"vegIntwatercourseLines\", \"FID_vegCoverUnion\", \"watercourse_lines_length\")\n",
    "replaceNone(\"vegCoverUnion\", \"watercourse_lines_length\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\jake.allen.ALLUVIUMQLD\\\\OneDrive - Alluvium Consulting Australia\\\\BiodiversityMBRC\\\\BiodiversityMBRC.gdb\\\\Basemap\\\\coreVegetationCategorised'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### VEG COVER DATA CLEANING\n",
    "\n",
    "# use pandas to clean dataset and manipulate columns\n",
    "arcpy.management.CalculateField(\"Basemap/vegCoverUnion\", \"Area_ha\", \"!Shape_Area! / 10000\", \"PYTHON3\", \"\", \"DOUBLE\")\n",
    "arcpy.management.AddField(\"Basemap/vegCoverUnion\", \"Vegetation_cover_type\", \"TEXT\")\n",
    "\n",
    "# combine vegetation cover columns\n",
    "with arcpy.da.UpdateCursor(\"Basemap/vegCoverUnion\", [\"Vegetation_cover_type\", \"Cover\", \"HVR\", \"VM_Status\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[1] != '' and row[1] is not None:\n",
    "            row[0] = row[1]\n",
    "        elif row[2] != '' and row[2] is not None:\n",
    "            row[0] = row[2]\n",
    "        elif row[3] != '' and row[3] is not None:\n",
    "            row[0] = row[3]\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "# combine percent and re changed columns\n",
    "with arcpy.da.UpdateCursor(\"Basemap/vegCoverUnion\", [\"percentage\", \"percent\", \"re_changed\", \"re_change\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] != '' and row[0] is not None:\n",
    "            row[1] = row[0]\n",
    "        if row[3] != '' and row[3] is not None:\n",
    "            row[2] = row[3]\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "# turn veg cover feature class into a dataframe\n",
    "df = pd.DataFrame.spatial.from_featureclass('Basemap/vegCoverUnion')[[\"Vegetation_cover_type\", \"percent\", \"current_re\", \"re_changed\",\n",
    "                                                                        \"vm_change\", \"Koala_habitat_area\", \"Watercourse_area_area\", \"Estuary_area\",\n",
    "                                                                        \"Reservoirs_area\", \"Lakes_area\", \"Canal_areas_area\", \"LSI_area\", \"Marine_swamp_area\", \"Saline_coastal_flat_area\",\n",
    "                                                                        \"Swamp_area\", 'Aquaculture_area', 'Settling_ponds_area', 'Salt_evaporators_area', 'Crayfish_pondage_area', 'Coastal_mngmnt_district_area',\n",
    "                                                                        \"Shorebird_roosts_area\", \"Riparian_woody_veg_area\", \"Sea_turtle_nesting_area\", 'watercourse_lines_length', \"Area_ha\",\n",
    "                                                                        \"SHAPE\"]]\n",
    "\n",
    "# recode vegetation cover type\n",
    "typeDict = {\n",
    "    'High Value Regrowth': 'High value regrowth',\n",
    "    'HVR': 'High value regrowth',\n",
    "    'remnant': 'Remnant',\n",
    "    'Remant': 'Remnant',\n",
    "    'non-rem': 'Non-remnant'\n",
    "}\n",
    "\n",
    "df['Vegetation_cover_type'] = df['Vegetation_cover_type'].replace(typeDict)\n",
    "\n",
    "# assign size category to patches\n",
    "def categorise_patches(area):\n",
    "    if area < 25:\n",
    "        category = \"<25 ha\"\n",
    "    elif 25 <= area < 50:\n",
    "        category = \"25 - <50 ha\"\n",
    "    elif 50 <= area < 100:\n",
    "        category = \"50 - <100 ha\"\n",
    "    elif 100 <= area < 150:\n",
    "        category = \"100 - <150 ha\"\n",
    "    elif 150 <= area < 200:\n",
    "        category = \"150 - <200 ha\"\n",
    "    else:\n",
    "        category = \">=200 ha\"\n",
    "    return category\n",
    "\n",
    "# assign numeric order based on size category\n",
    "catOrder = {\n",
    "    \"<25 ha\": 1,\n",
    "    \"25 - <50 ha\": 2,\n",
    "    \"50 - <100 ha\": 3,\n",
    "    \"100 - <150 ha\": 4,\n",
    "    \"150 - <200 ha\": 5,\n",
    "    \">=200 ha\": 6\n",
    "}\n",
    "\n",
    "df['Size_category'] = df[\"Area_ha\"].apply(categorise_patches)\n",
    "df['Size_order'] = df['Size_category'].map(catOrder)\n",
    "df.spatial.to_featureclass(\"BiodiversityMBRC.gdb/Basemap/coreVegetationCategorised\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Summarise area values\n",
    "\n",
    "cols = ['Area_ha',\n",
    "        'Riparian_woody_veg_area',\n",
    "        'Shorebird_roosts_area',\n",
    "        'Swamp_area',\n",
    "        'Saline_coastal_flat_area',\n",
    "        'Marine_swamp_area',\n",
    "        'LSI_area',\n",
    "        'Canal_areas_area',\n",
    "        'Lakes_area',\n",
    "        'Reservoirs_area',\n",
    "        'Estuary_area',\n",
    "        'Watercourse_area_area',\n",
    "        'Aquaculture_area',\n",
    "        'Settling_ponds_area',\n",
    "        'Salt_evaporators_area',\n",
    "        'Crayfish_pondage_area',\n",
    "        'Coastal_mngmnt_district_area',\n",
    "        'watercourse_lines_length',\n",
    "        'Koala_habitat_area']\n",
    "\n",
    "dfSum = df.groupby('Size_category', as_index=False)[cols].sum()\n",
    "dfSum['Count'] = df.groupby('Size_category').size().values\n",
    "#dfSum = df.groupby('Size_category', as_index=False).agg({**{col: 'sum' for col in cols},\n",
    "                                      # 'Size_category':'size'}).reset_index()\n",
    "\n",
    "cols.remove('Area_ha')\n",
    "dfSum[cols] /= 10000\n",
    "\n",
    "#dfSum.rename(columns={'Size_category': 'Count'}, inplace=True)\n",
    "\n",
    "# assign numeric order based on size category\n",
    "catOrder = {\n",
    "    \"<25 ha\": 1,\n",
    "    \"25 - <50 ha\": 2,\n",
    "    \"50 - <100 ha\": 3,\n",
    "    \"100 - <150 ha\": 4,\n",
    "    \"150 - <200 ha\": 5,\n",
    "    \">=200 ha\": 6\n",
    "}\n",
    "\n",
    "dfSum['Size_order'] = dfSum['Size_category'].map(catOrder)\n",
    "\n",
    "cols.append('Area_ha')\n",
    "\n",
    "# compute percentages\n",
    "for col in cols:\n",
    "    dfSum[col + '_pc'] = (dfSum[col] / dfSum[col].sum()) * 100\n",
    "    \n",
    "dfSum.fillna(0)\n",
    "\n",
    "dfSum.to_csv(\"contextLayerAreaSummary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Summarise by vegetation type\n",
    "\n",
    "dfVeg = df.groupby('Vegetation_cover_type', as_index=False)['Area_ha'].sum()\n",
    "dfVeg['Count'] = df.groupby('Vegetation_cover_type').size().values\n",
    "dfVeg['Area_ha_pc'] = (dfVeg['Area_ha'] / dfVeg['Area_ha'].sum()) * 100\n",
    "dfVeg.to_csv(\"vegetationCoverTypesAreaSummary.csv\", index=-False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, 5 January 2024 10:49:29 AM\",\"Succeeded at Friday, 5 January 2024 10:49:31 AM (Elapsed Time: 2.36 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'stepstonesJoin'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### CREATE STEPPING-STONE DATASET\n",
    "\n",
    "if arcpy.Exists(\"Processing\"):\n",
    "    arcpy.Delete_management(\"Processing\")\n",
    "\n",
    "arcpy.management.CreateFeatureDataset(gdb, 'Processing', arcpy.Describe(f'{gdb}/Input').spatialReference.name)\n",
    "\n",
    "# pull out polygons under 25 hectares from previously merged vegetation polygon dataset\n",
    "arcpy.management.MakeFeatureLayer(\"Basemap/coreVegetationCategorised\", \"stepstones\", \"Area_ha < 25\")\n",
    "\n",
    "# compute canopy statistics using canopy height model and zonal statistics\n",
    "if not arcpy.Exists(\"chTable\"):\n",
    "    arcpy.sa.ZonalStatisticsAsTable(\"stepstones\", \"OBJECTID\", \"vcslidar18001\", \"chTable\", \"NODATA\", \"ALL\")\n",
    "\n",
    "# join zonal stats to stepstones\n",
    "arcpy.management.CopyFeatures(\"stepstones\", \"Processing/stepstonesJoin\")\n",
    "arcpy.management.JoinField(\"stepstonesJoin\", \"OBJECTID\", \"chTable\", \"OBJECTID_1\", [\"MEDIAN\", \"MIN\", \"MAX\", \"RANGE\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\jake.allen.ALLUVIUMQLD\\\\OneDrive - Alluvium Consulting Australia\\\\BiodiversityMBRC\\\\BiodiversityMBRC.gdb\\\\Basemap\\\\steppingStonesVegetationCategorised'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### STEPPING STONES DATA CLEANING\n",
    "\n",
    "step = pd.DataFrame.spatial.from_featureclass(\"Processing/stepstonesJoin\")[[\"vegetation_cover_type\", \"size_category\", \"percent\", \"current_re\", \"re_changed\",\n",
    "                                                                            \"vm_change\", \"MEDIAN\", \"MAX\", \"MIN\", \"RANGE\", \"koala_habitat_area\", \"watercourse_area_area\", \"estuary_area\",\n",
    "                                                                            \"reservoirs_area\", \"lakes_area\", \"canal_areas_area\", \"lsi_area\", \"marine_swamp_area\", \"saline_coastal_flat_area\",\n",
    "                                                                            \"swamp_area\",  'aquaculture_area', 'settling_ponds_area', 'salt_evaporators_area', 'crayfish_pondage_area', 'coastal_mngmnt_district_area',\n",
    "                                                                            \"shorebird_roosts_area\", \"riparian_woody_veg_area\", \"sea_turtle_nesting_area\",  'watercourse_lines_length', \"area_ha\",\n",
    "                                                                            \"size_order\", \"SHAPE\"]]\n",
    "step.rename(columns={\"MEDIAN\": \"median_tree_height\",\n",
    "                    \"MAX\": \"maximum_tree_height\",\n",
    "                    \"MIN\": \"minimum_tree_height\",\n",
    "                    \"RANGE\": \"tree_height_range\"}, inplace=True)\n",
    "\n",
    "# assign size category to stepping stones\n",
    "def categorise_stepping_stones(area):\n",
    "    if area < 5:\n",
    "        category = \"<5 ha\"\n",
    "    elif 5 <= area < 10:\n",
    "        category = \"5 - <10 ha\"\n",
    "    elif 10 <= area < 25:\n",
    "        category = \"10 - <25 ha\"\n",
    "    return category\n",
    "\n",
    "step[\"size_category\"] = step[\"area_ha\"].apply(categorise_stepping_stones)\n",
    "\n",
    "# assign numeric order based on size category\n",
    "catOrder = {\n",
    "    \"<5 ha\": 1,\n",
    "    \"5 - <10 ha\": 2,\n",
    "    \"10 - <25 ha\": 3\n",
    "}\n",
    "\n",
    "step['size_order'] = step['size_category'].map(catOrder)\n",
    "step.rename(columns={'MEDIAN': \"median_canopy_height\"}, inplace=True)\n",
    "\n",
    "\n",
    "step.spatial.to_featureclass(\"BiodiversityMBRC.gdb/Basemap/steppingStonesVegetationCategorised\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Summarise stepping stones by context layers\n",
    "\n",
    "cols = ['koala_habitat_area',\n",
    "       'area_ha']\n",
    "\n",
    "stepSum = step.groupby('size_category', as_index=False)[cols].sum()\n",
    "stepSum['count'] = step.groupby('size_category').size().values\n",
    "#dfSum = df.groupby('Size_category', as_index=False).agg({**{col: 'sum' for col in cols},\n",
    "                                      # 'Size_category':'size'}).reset_index()\n",
    "\n",
    "cols.remove('area_ha')\n",
    "stepSum[cols] /= 10000\n",
    "\n",
    "#dfSum.rename(columns={'Size_category': 'Count'}, inplace=True)\n",
    "\n",
    "# assign numeric order based on size category\n",
    "catOrder = {\n",
    "    \"<5 ha\": 1,\n",
    "    \"5 - <10 ha\": 2,\n",
    "    \"10 - <25 ha\": 3\n",
    "}\n",
    "\n",
    "stepSum['size_order'] = stepSum['size_category'].map(catOrder)\n",
    "\n",
    "cols.append('area_ha')\n",
    "\n",
    "# compute percentages\n",
    "for col in cols:\n",
    "    stepSum[col + '_pc'] = (stepSum[col] / stepSum[col].sum()) * 100\n",
    "    \n",
    "stepSum.fillna(0)\n",
    "\n",
    "stepSum.to_csv(\"steppingStonesAreaSummary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Summarise stepping stones by vegetation cover\n",
    "\n",
    "stepVeg = step.groupby('vegetation_cover_type', as_index=False)['area_ha'].sum()\n",
    "stepVeg['count'] = step.groupby('vegetation_cover_type').size().values\n",
    "stepVeg['area_ha_pc'] = (stepVeg['area_ha'] / stepVeg['area_ha'].sum()) * 100\n",
    "stepVeg.to_csv(\"vegetationCoverTypesSteppingStonesAreaSummary.csv\", index=-False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATE ECOLOGICAL CORRIDORS DATASET\n",
    "\n",
    "if arcpy.Exists(\"Processing\"):\n",
    "    arcpy.Delete_management(\"Processing\")\n",
    "\n",
    "arcpy.management.CreateFeatureDataset(gdb, 'Processing', arcpy.Describe(f'{gdb}/Input').spatialReference.name)\n",
    "\n",
    "# in order to merge datasets, geometries where the two datasets cooincide must be exact.\n",
    "# copy datasets to processing and snap the two together\n",
    "arcpy.management.CopyFeatures(\"Input/MBRC_PlanningScheme_OM_EnvironmentalOffsets\", \"Processing/offsets\")\n",
    "arcpy.management.MakeFeatureLayer(\"Processing/offsets\", \"offsets\")\n",
    "arcpy.management.CopyFeatures(\"Input/MBRC_CNCCS_Ecological_Corridors\", \"Processing/ecoCorridors\")\n",
    "arcpy.management.MakeFeatureLayer(\"Processing/ecoCorridors\", \"ecoCorridors\")\n",
    "arcpy.edit.Snap(\n",
    "    in_features=\"ecoCorridors\",\n",
    "    snap_environment=\"offsets EDGE '15 Meters';offsets VERTEX '15 Meters';offsets END '15 Meters'\"\n",
    ")\n",
    "# merge datasets by performing union\n",
    "arcpy.analysis.Union(\"offsets;ecoCorridors\", \"Processing/ecoCorridorsUnion\")\n",
    "\n",
    "# assign feature type\n",
    "arcpy.management.CalculateField(\"ecoCorridorsUnion\", \"feature_type\", \"''\", \"PYTHON3\", \"\",  \"TEXT\")\n",
    "with arcpy.da.UpdateCursor(\"ecoCorridorsUnion\", [\"OVL2_DESC\", \"NAME\", \"feature_type\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None and row[0] != '' and row[1] is not None and row[1] != '':\n",
    "            row[2] = \"Both offset receiving area and ecological corridor\"\n",
    "        elif row[1] is not None and row[1] != '':\n",
    "            row[2] = \"Ecological corridor\"\n",
    "        else:\n",
    "            row[2] = \"Offset receiving area\"\n",
    "        cursor.updateRow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\jake.allen.ALLUVIUMQLD\\\\OneDrive - Alluvium Consulting Australia\\\\BiodiversityMBRC\\\\BiodiversityMBRC.gdb\\\\Basemap\\\\ecologicalCorridorsCategorised'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean and export ecological corridors\n",
    "\n",
    "corDf = pd.DataFrame.spatial.from_featureclass(\"Processing/ecoCorridorsUnion\")[[\"OVL2_DESC\", \"OVL2_CAT\", \"ID\", \"YEAR\", \"NAME\", \"RANK\", \"feature_type\", \"SHAPE\"]]\n",
    "rankMap = {'1': '350m',\n",
    "          '2': '200m',\n",
    "          '3': '100m'} \n",
    "corDf['corridor_width'] = corDf['RANK'].map(rankMap)\n",
    "\n",
    "corDf.spatial.to_featureclass(\"BiodiversityMBRC.gdb/Basemap/ecologicalCorridorsCategorised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\jake.allen.ALLUVIUMQLD\\\\OneDrive - Alluvium Consulting Australia\\\\BiodiversityMBRC\\\\BiodiversityMBRC.gdb\\\\Basemap\\\\restorationAreas'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RESTORATION AREAS\n",
    "\n",
    "if arcpy.Exists(\"Processing\"):\n",
    "    arcpy.Delete_management(\"Processing\")\n",
    "\n",
    "arcpy.management.CreateFeatureDataset(gdb, 'Processing', arcpy.Describe(f'{gdb}/Input').spatialReference.name)\n",
    "\n",
    "# Union Veg Cover Union and Ecological Corridors\n",
    "arcpy.analysis.Union(\"Basemap/ecologicalCorridorsCategorised;Basemap/coreVegetationCategorised\", \"Processing/vegCoverCorridorUnion\")\n",
    "\n",
    "# copy just the veg areas that not within an ecological corridor or offest receiving area\n",
    "arcpy.management.MakeFeatureLayer(\"Processing/vegCoverCorridorUnion\", \"vegCoverCorridorUnion\", \"FID_coreVegetationCategorised = -1\")\n",
    "arcpy.management.CopyFeatures(\"vegCoverCorridorUnion\", \"Processing/restorationAreasProcessing\")\n",
    "  \n",
    "# keep only necessary attributes\n",
    "resto = pd.DataFrame.spatial.from_featureclass(\"Processing/restorationAreasProcessing\")[[\"vegetation_cover_type\", \"current_re\", \"percent\", \"FID_ecologicalCorridorsCategorised\", \"feature_type\", \"SHAPE\"]]\n",
    "resto.rename(columns={\"FID_ecologicalCorridorsCategorised\": \"eco_corridor_id\"}, inplace=True)\n",
    "resto.spatial.to_featureclass(\"BiodiversityMBRC.gdb/Basemap/restorationAreas\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "if arcpy.Exists(\"Processing\"):\n",
    "    arcpy.Delete_management(\"Processing\")\n",
    "\n",
    "arcpy.management.CreateFeatureDataset(gdb, 'Processing', arcpy.Describe(f'{gdb}/Input').spatialReference.name)\n",
    "\n",
    "# convert any big integer fields types\n",
    "fcs = [\"Basemap/coreVegetationCategorised\", \"Basemap/steppingStonesVegetationCategorised\"]\n",
    "\n",
    "for fc in fcs:\n",
    "    df = pd.DataFrame.spatial.from_featureclass(fc)\n",
    "    fcName = fc.split('/')[-1]\n",
    "    # export table to csv\n",
    "    csv = df.drop('SHAPE', axis = 1).to_csv(f'{fcName}_table.csv')\n",
    "    # import csv to geodatabase\n",
    "    arcpy.conversion.TableToGeodatabase(f'{fcName}_table.csv', \"BiodiversityMBRC.gdb\")\n",
    "    intab = f'{fcName}_table'\n",
    "    # export just object id from target fc\n",
    "    fmappings = arcpy.FieldMappings()\n",
    "    fmap = arcpy.FieldMap()\n",
    "    fmap.addInputField(fc, \"OBJECTID\")\n",
    "    fmappings.addFieldMap(fmap)\n",
    "    arcpy.conversion.FeatureClassToFeatureClass(fc, f'{arcpy.env.workspace}/Processing', f'{fcName}_cleaned', '',  fmappings)\n",
    "    # join fields \n",
    "    jflds = [field.name for field in arcpy.ListFields(fc)]\n",
    "    arcpy.management.JoinField(f'Processing/{fcName}_cleaned', \"OBJECTID\", intab, \"OBJECTID\")\n",
    "    outfc = f'Basemap/{fcName}_clean' \n",
    "    arcpy.management.CopyFeatures(f'Processing/{fcName}_cleaned', outfc)\n",
    "    for field in arcpy.ListFields(outfc):\n",
    "        if field.name not in jflds:\n",
    "            arcpy.management.DeleteField(outfc, field.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add feature ID cols to network map elements\n",
    "\n",
    "vegDict = {'coreVegetationCategorised_clean': 'core_area_id',\n",
    "          'steppingStonesVegetationCategorised_clean': 'stepping_stone_id',\n",
    "          'ecologicalCorridorsCategorised': 'eco_corridor_id',\n",
    "          'restorationAreas': 'restoration_area_id'}\n",
    "\n",
    "for dset, fid in vegDict.items():\n",
    "    arcpy.management.CalculateField(f'Basemap/{dset}', fid, '!OBJECTID!', 'PYTHON3', None, 'SHORT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      OBJECTID  Value        Count\n",
      "0            1      0  992662351.0\n",
      "1            2     50     981069.0\n",
      "2            3     51    1561326.0\n",
      "3            4     52    1993486.0\n",
      "4            5     53    1121238.0\n",
      "...        ...    ...          ...\n",
      "9973      9974  10090          1.0\n",
      "9974      9975  10115          1.0\n",
      "9975      9976  10117          1.0\n",
      "9976      9977  10148          1.0\n",
      "9977      9978  10882          1.0\n",
      "\n",
      "[9978 rows x 3 columns]\n",
      "  height_category   cell_count     area_ha\n",
      "0               0  992662351.0  99266.2351\n",
      "1           >0-3m  293802188.0  29380.2188\n",
      "2          >3-10m  265444102.0  26544.4102\n",
      "3         >10-30m  856146366.0  85614.6366\n",
      "4         >30-50m  121054665.0  12105.4665\n",
      "5            >50m    1191382.0    119.1382\n",
      "  height_category  step_cell_count  step_area_ha\n",
      "0               0       37276893.0     3727.6893\n",
      "1           >0-3m        9938874.0      993.8874\n",
      "2          >3-10m       30364027.0     3036.4027\n",
      "3         >10-30m      125135484.0    12513.5484\n",
      "4         >30-50m        5444951.0      544.4951\n",
      "5            >50m          18302.0        1.8302\n",
      "  height_category   cell_count  ...  step_area_ha  step_canopy_proportion\n",
      "0               0  992662351.0  ...     3727.6893                0.037552\n",
      "1           >0-3m  293802188.0  ...      993.8874                0.033828\n",
      "2          >3-10m  265444102.0  ...     3036.4027                0.114390\n",
      "3         >10-30m  856146366.0  ...    12513.5484                0.146161\n",
      "4         >30-50m  121054665.0  ...      544.4951                0.044979\n",
      "5            >50m    1191382.0  ...        1.8302                0.015362\n",
      "\n",
      "[6 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# summarise canopy raster within/outside conservation network\n",
    "from arcgis.features import GeoAccessor\n",
    "\n",
    "if not arcpy.Exists('vcslidar18001_int'):\n",
    "    canopy = Int(Raster(\"vcslidar18001\") * 100)\n",
    "    canopy.save('vcslidar18001_int')\n",
    "\n",
    "if not arcpy.Exists('canopyExportTable_all'): \n",
    "    arcpy.conversion.ExportTable(\"vcslidar18001_int\", 'canopyExportTable_all')\n",
    "\n",
    "canDf = GeoAccessor.from_table('BiodiversityMBRC.gdb/canopyExportTable_all')\n",
    "print(canDf)\n",
    "\n",
    "#recode = [df['Value'] <= 3, (df['Value'] > 3) & (df['Value'] <= 10), (df['Value'] > 10) & (df['Value'] <= 30), (df['Value'] > 30) & (df['Value'] <= 50), (df['Value'] > 50)]\n",
    "labels = ['0', '>0-3m', '>3-10m', '>10-30m', '>30-50m', '>50m']\n",
    "canDf['height_category'] = pd.cut(canDf['Value'], bins = [0,50,300,1000,3000,5000, float('inf')], labels=labels, right=False)\n",
    "\n",
    "# Group by size category and summarise area\n",
    "canSum = canDf.groupby('height_category', as_index=False)['Count'].sum()\n",
    "canSum['area_ha'] = canSum['Count'] / 10000\n",
    "canSum.rename(columns={'Count':'cell_count'}, inplace=True)\n",
    "# stepSum['count'] = step.groupby('size_category').size().values\n",
    "print(canSum)\n",
    "\n",
    "# Summarise stepping stone canopy\n",
    "if not arcpy.Exists('canopyHeightSteppingStones_int'):\n",
    "    step = Raster(\"canopyHeightSteppingStones\") * 100\n",
    "    step.save('canopyHeightSteppingStones_int')\n",
    "  \n",
    "if not arcpy.Exists('canopyExportTable_steppingStones'):\n",
    "    arcpy.conversion.ExportTable(\"canopyHeightSteppingStones_int\", 'canopyExportTable_steppingStones')\n",
    "\n",
    "stepDf = GeoAccessor.from_table('BiodiversityMBRC.gdb/canopyExportTable_steppingStones')\n",
    "stepDf['height_category'] = pd.cut(stepDf['Value'], bins = [0,50,300,1000,3000,5000, float('inf')], labels=labels, right=False)\n",
    "# Group by size category and summarise area\n",
    "stepSum = stepDf.groupby('height_category', as_index=False)['Count'].sum()\n",
    "stepSum['area_ha'] = stepSum['Count'] / 10000\n",
    "stepSum.rename(columns={'Count':'step_cell_count',\n",
    "                       'area_ha': 'step_area_ha'}, inplace=True)\n",
    "print(stepSum)\n",
    "\n",
    "mergeSum = pd.merge(canSum, stepSum, on='height_category', how='left')\n",
    "mergeSum['step_canopy_proportion'] = mergeSum['step_area_ha'] / mergeSum['area_ha']\n",
    "print(mergeSum)\n",
    "\n",
    "mergeSum.to_csv('steppingStonesTreeCanopyAnalysis.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
